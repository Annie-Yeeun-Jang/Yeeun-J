{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "make_data_by_discriminator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Annie-Yeeun-Jang/Yeeun-J/blob/master/text_conf/make_data_by_discriminator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxHHpZ6YtFyj",
        "outputId": "c6b3985b-9c01-42bb-b8fd-7693b9dcaef6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tVa-3mxtlc_"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnQHODXSIuZD"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRbUpfoIr9eB"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preliminaries\n",
        "\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "\n",
        "# Models\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Training\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "# Evaluation\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "#source_folder = '/content/drive/My Drive/transformers/Data'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seJJVGHzsNc5"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJqlHRaesPDp"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtNLo9HZsA9P"
      },
      "source": [
        "destination_folder = '/content/drive/Shareddrives/text_conf/discriminator/check_point/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oadkrh8BsTUL"
      },
      "source": [
        "MAX_SEQ_LEN = 128\n",
        "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
        "text_field = Field(use_vocab=False, tokenize=tokenizer.encode,is_target = True, lower=False, include_lengths=False, batch_first=True,\n",
        "                   fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlFMx4rcsY66"
      },
      "source": [
        "class BERT(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "\n",
        "        options_name = \"bert-base-uncased\"\n",
        "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
        "\n",
        "    def forward(self, text, label):\n",
        "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
        "\n",
        "        return loss, text_fea"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUESUV1yscdk"
      },
      "source": [
        "model = BERT().to(device)\n",
        "state_dict = torch.load(destination_folder + 'model.pt', map_location=device)\n",
        "model.load_state_dict(state_dict['model_state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98_2JTwqseDh"
      },
      "source": [
        "tabular = TabularDataset(path=\"/content/drive/Shareddrives/text_conf/dataset/preprocessed/discriminator/with_academic_len32.csv\", format='CSV', fields=[('text', text_field)], skip_header=True)\n",
        "# Iterators\n",
        "data_iter = Iterator(tabular, batch_size=16, device=device, train=False, shuffle=False, sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqgPOm8aVApe"
      },
      "source": [
        "tokenizer.decode(next(iter(data_iter)).text[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKCjeamRVXLG"
      },
      "source": [
        "original = pd.read_csv(\"/content/drive/Shareddrives/text_conf/dataset/preprocessed/discriminator/with_academic_len32.csv\").text.tolist()\n",
        "original_batch = []\n",
        "for batch in range(len(original)//16 + 1):\n",
        "  original_batch.append(original[batch:(1+batch)*16])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLBmWBpN0QDR"
      },
      "source": [
        "threshold = 0.9\n",
        "softmax = nn.Softmax(dim = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLHSq46Isijd"
      },
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  native = []\n",
        "  nonnative = []\n",
        "  for (i, (iter)), original_text in zip(enumerate(data_iter), original_batch):\n",
        "    text = iter.text.type(torch.LongTensor).to(device)\n",
        "    label = torch.tensor([0]*len(text), dtype = torch.long).to(device)\n",
        "    _, tmp = model(text, label)\n",
        "\n",
        "    result = tmp.to('cpu')\n",
        "\n",
        "    softmax_dist = softmax(result)\n",
        "    argmax_idx = torch.argmax(softmax_dist, dim = 1)\n",
        "    confidence_list = [dist[idx] for dist, idx in zip(softmax_dist, argmax_idx)]\n",
        "    \n",
        "    native_text = [line for line, idx, confidence in zip(original_text, argmax_idx, confidence_list) if idx == 0 and confidence > threshold]\n",
        "    nonnative_text = [line for line, idx, confidence in zip(original_text, argmax_idx, confidence_list) if idx == 1 and confidence > threshold]\n",
        "\n",
        "    native.extend(native_text)\n",
        "    nonnative.extend(nonnative_text)\n",
        "\n",
        "    if i % 300 == 0:\n",
        "      print(f\"{i}/{len(data_iter)} 배치 완료\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLCSsDzO6gYV"
      },
      "source": [
        "print(len(native), len(nonnative))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuI6Zku_YlKM"
      },
      "source": [
        "nonnative[-10:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irp4igKzK0m-"
      },
      "source": [
        "# train test val 나눠서 저장하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SREtF0XU_KIV"
      },
      "source": [
        "native_idx = round(len(native)*0.9)\n",
        "nonnative_idx = round(len(nonnative)*0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrftCfTc_U2I"
      },
      "source": [
        "import random\n",
        "random.shuffle(native)\n",
        "random.shuffle(nonnative)\n",
        "\n",
        "native_train = native[:native_idx]\n",
        "native_test = native[native_idx:]\n",
        "\n",
        "nonnative_train = nonnative[:nonnative_idx]\n",
        "nonnative_test = nonnative[nonnative_idx:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WO16dFD69UU"
      },
      "source": [
        "native_train_pd = pd.DataFrame(native_train)\n",
        "native_test_pd = pd.DataFrame(native_test)\n",
        "\n",
        "nonnative_train_pd = pd.DataFrame(nonnative_train)\n",
        "nonnative_test_pd = pd.DataFrame(nonnative_test)\n",
        "\n",
        "native_train_pd.to_csv(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/native_train2.csv\", header=None, index = None)\n",
        "native_test_pd.to_csv(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/native_test2.csv\", header=None, index = None)\n",
        "\n",
        "nonnative_train_pd.to_csv(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/nonnative_train2.csv\", header=None, index = None)\n",
        "nonnative_test_pd.to_csv(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/nonnative_test2.csv\", header=None, index = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhbOMMRtCtKS"
      },
      "source": [
        "# 문장 길이 짧은거 없애기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1e32dfCDDyv"
      },
      "source": [
        "pd.read_csv(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/native_train2.csv\").text.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjMvMSw0M3Oy"
      },
      "source": [
        "import pandas as pd\n",
        "native_train = pd.read_csv(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/native_train2.csv\", header= None)\n",
        "native_test = pd.read_csv(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/native_test2.csv\", header= None)\n",
        "\n",
        "nonnative_train = pd.read_csv(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/nonnative_train2.csv\", header= None)\n",
        "nonnative_test = pd.read_csv(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/nonnative_test2.csv\", header= None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBlAY5pWDpDE"
      },
      "source": [
        "with open(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/native_train2.csv\", \"r\") as f:\n",
        "    native_train= f.readlines()\n",
        "with open(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/native_test2.csv\", \"r\") as f:\n",
        "    native_test= f.readlines()\n",
        "\n",
        "with open(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/nonnative_train2.csv\", \"r\") as f:\n",
        "    nonnative_train= f.readlines()\n",
        "with open(\"/content/drive/Shareddrives/text_conf/dataset/styletransformer/nonnative_test2.csv\", \"r\") as f:\n",
        "    nonnative_test= f.readlines()\n",
        "    "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l-zHtueCsmf"
      },
      "source": [
        "native_train = list(filter(lambda x: len(x)>20, native_train))\n",
        "native_test = list(filter(lambda x: len(x)<20, native_test))\n",
        "nonnative_train = list(filter(lambda x: len(x)<20, nonnative_train))\n",
        "nonnative_test = list(filter(lambda x: len(x)<30, nonnative_test))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ17jgLzC0-2",
        "outputId": "c9ecd9fd-589f-4ba1-a9c2-874e6d95ded8"
      },
      "source": [
        "native_test"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"One of Hank Jr . '\\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fkq2jICgEVip",
        "outputId": "e6219343-970c-4fc1-8eea-b58b576a46ea"
      },
      "source": [
        "nonnative_test"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['They will not be stifled .\\n',\n",
              " '\"Again , as Boggess et al.\"\\n',\n",
              " 'No one had a glib answer .\\n',\n",
              " 'It was painful for her .\\n',\n",
              " '\"Again , as Boggess et al.\"\\n',\n",
              " 'She was far away from home .\\n',\n",
              " 'The very presence of U.N .\\n',\n",
              " 'The answer is probably yes .\\n',\n",
              " 'NUM  million out of  NUM .\\n',\n",
              " 'I told him it was too late .\\n',\n",
              " 'The new prize is Asia .\\n',\n",
              " 'NUM  million out of  NUM .\\n',\n",
              " 'NUM  billion for the year .\\n',\n",
              " '\"Who will want her ? \"\"\"\\n',\n",
              " 'NUM  billion for the year .\\n',\n",
              " 'No one had a glib answer .\\n',\n",
              " 'Birth then was a ceremony .\\n',\n",
              " \"do n't over speak ; .\\n\",\n",
              " 'NUM  million out of  NUM .\\n',\n",
              " '\", Stony Point , NY  NUM  .\"\\n',\n",
              " '\"NUM   NUM  , p = .\"\\n',\n",
              " 'NUM  billion for the year .\\n',\n",
              " 'That is the first problem .\\n',\n",
              " 'That is the first problem .\\n',\n",
              " '\"Again , as Boggess et al.\"\\n',\n",
              " 'That is the first problem .\\n',\n",
              " 'The new prize is Asia .\\n',\n",
              " 'And now they are thriving .\\n',\n",
              " 'I told him it was too late .\\n',\n",
              " 'Where does it come from ?\\n',\n",
              " 'NUM  billion for the year .\\n',\n",
              " 'No one had a glib answer .\\n',\n",
              " 'I told him it was too late .\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1bERVo7Eb-d"
      },
      "source": [
        "native_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZD02bqVEl35"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}